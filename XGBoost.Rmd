---
title: "XGBoost"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(data.table)
library(caTools)
library(xgboost)
library(caret)
library(ROCR)

credit_card_raw = fread("creditcard.csv")

# Create train and test dataset
credit_card_raw[, test:=0]
credit_card_raw[, "Time":= NULL]
credit_card_raw[sample(nrow(credit_card_raw), 284807*0.2), test:=1]
test <- credit_card_raw[test==1]
train <- credit_card_raw[test==0]
train[, "test" := NULL]
test[, "test" := NULL]
credit_card_raw[, "test" := NULL]

# Convert datatables to dataframes for downsampling
setDF(train)
setDF(test)

# Downsample
set.seed(1)
train$Class <- factor(train$Class)
downsample.train <- downSample(train[, -ncol(train)], train$Class)

test$Class <- factor(test$Class)
downsample.test <- downSample(test[, -ncol(test)], test$Class)


# Fit XGBoost model
xgb = xgboost(data=data.matrix(downsample.train[,1:29])
              ,label=as.numeric(downsample.train$Class)-1
              ,objective = "binary:logistic"
              ,max.depth = 2
              ,eta = 1
              ,nthread = 2
              ,nrounds = 25)
```

```{r}
# Measure model performance on training set
pred = predict(xgb, data.matrix(downsample.train[,1:29]))
pred = as.numeric(pred>0.5)
print(head(pred))
training_accuracy = mean(pred==(as.numeric(downsample.train$Class)-1))
print(paste("Model accuracy on training set:", training_accuracy))
# Confusion matrix for training set
confusionMatrix(as.factor(pred), downsample.train$Class
                ,dnn=c("Prediction", "Reference"))
# Plot ROC curve
pred_roc = prediction(pred, as.numeric(downsample.train$Class)-1)
roc_train = performance(pred_roc, "tpr", "fpr")

plot(roc_train, lwd=3, main="ROC Curve (Training Set)"
     ,xlab="False Positive Rate", ylab="True Positive Rate")
```

```{r}
# Apply XGBoost model on test set
predictions = predict(xgb, data.matrix(downsample.test[,1:29]))
length(predictions) == dim(downsample.test)[1]
# Transform predictions to binary results
predictions = as.numeric(predictions>0.5)
print(head(predictions))
# Measure model performance on test set
test_accuracy = mean(predictions==(as.numeric(downsample.test$Class)-1))
print(paste("Model accuracy on test set:", test_accuracy))
# Confusion matrix for test set
confusionMatrix(as.factor(predictions), downsample.test$Class
                ,dnn=c("Prediction", "Reference"))
# Plot ROC curve
predictions_roc = prediction(predictions, as.numeric(downsample.test$Class)-1)
roc_test = performance(predictions_roc, "tpr", "fpr")

plot(roc_test, lwd=3, main="ROC Curve (Test Set)"
     ,xlab="False Positive Rate", ylab="True Positive Rate")
```

```{r}
# Apply XGBoost model on raw dataset
yhat = predict(xgb, data.matrix(credit_card_raw[,1:29]))
length(yhat) == dim(credit_card_raw)[1]
# Transform predictions to binary results
yhat = as.numeric(yhat>0.5)
print(head(yhat))
# Measure model performance
raw_accuracy = mean(yhat==credit_card_raw$Class)
print(paste("Model accuracy on raw data:", raw_accuracy))
# Confusion matrix
confusionMatrix(as.factor(yhat), as.factor(credit_card_raw$Class)
                ,dnn=c("Prediction", "Reference"))
# Plot ROC curve
yhat_roc = prediction(yhat, credit_card_raw$Class)
roc_raw = performance(yhat_roc, "tpr", "fpr")

plot(roc_raw, lwd=3, main="ROC Curve (Raw Dataset)"
     ,xlab="False Positive Rate", ylab="True Positive Rate")
```

```{r}
# Downsample the raw dataset: 492 frauds & 492 non-frauds
df = setDF(credit_card_raw)
df$Class = factor(df$Class)
downsample.df = downSample(df[,-ncol(df)], df$Class)
# XGBoost with cross-validation
xgb_cv = xgb.cv(data=data.matrix(downsample.df[,1:29])
                ,label=as.numeric(downsample.df$Class)-1
                ,objective = "binary:logistic"
                ,max.depth = 3
                ,eta = 1
                ,nthread = 2
                ,nrounds = 4
                ,nfold = 5
                ,metrics=list("rmse","auc"))
print(xgb_cv)
```



